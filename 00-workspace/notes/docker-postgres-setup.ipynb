{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6f8373",
   "metadata": {},
   "source": [
    "## üê≥ Step 1: Set Up Docker Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098f07a",
   "metadata": {},
   "source": [
    "To get our environment set up, we'll create two config files. \n",
    "\n",
    "1. Dockerfile\n",
    "2. docker-compose.yaml\n",
    "\n",
    "| **File** | **Purpose** |\n",
    "|---------|-------------|\n",
    "| `Dockerfile` | Defines your service‚Äôs environment (e.g., Python version, packages). |\n",
    "| `docker-compose.yaml` | Coordinates how containers are built and run ‚Äî incl. ports, volumes, and dependencies (Postgres etc).|\n",
    "\n",
    "#### üß† Docker Compose Mental Model\n",
    "\n",
    "Instead of running manual Docker commands, Compose simplifies the workflow:\n",
    "\n",
    "| **Goal** | **What Compose Does** | **Where It's Defined** |\n",
    "|----------|------------------------|--------------------------|\n",
    "| Define your app's image | Builds it from your `Dockerfile` | `docker-compose.yaml ‚Üí build:` |\n",
    "| Run your app + services | Launches containers for each service (app, Postgres, etc.) | `docker-compose.yaml ‚Üí services:` |\n",
    "| Share files between local + container | Mounts local folders inside containers | `docker-compose.yaml ‚Üí volumes:` |\n",
    "| Talk to the database | Exposes ports for local access | `docker-compose.yaml ‚Üí ports:` |\n",
    "| Start everything | `docker-compose up` | CLI command |\n",
    "| Stop everything | `docker-compose down` | CLI command |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0339d",
   "metadata": {},
   "source": [
    "## Step 2: Run Postgres on Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4ff8b",
   "metadata": {},
   "source": [
    "- Create a `docker-compose.yaml` file to define the Postgres service and credentials:\n",
    "  - Use the official Postgres image (`postgres:13`) from Docker Hub.\n",
    "  - Use a **named volume** (`pgdata:/var/lib/postgresql/data`) to persist db data cleanly.\n",
    "  - Note: DE Zoomcamp used a bind mount method, but **named volumes** is preferred as the data is managed by Docker\n",
    "\n",
    "- Start the Postgres container from directory containing `docker-compose.yaml` :\n",
    "  ```bash\n",
    "  docker-compose up -d\n",
    "- Install pgcli, a Postgres CLI client for easy SQL queries from the terminal:\n",
    "  ```bash \n",
    "  pip install pgcli \n",
    "- Connect to the running Postgres container with:\n",
    "  ```bash \n",
    "  pgcli -h localhost -p 5432 -u root -d nyc_taxi\n",
    "  ```\n",
    "  **Translation**\n",
    "‚ÄúHey, connect to the Postgres server running on my machine (`localhost`), using port `5432`, log in as user `root`, and access the db named `nyc_taxi`.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17730631",
   "metadata": {},
   "source": [
    "## üêº Step 3: Download Taxi Data & Read CSV with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c9dec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Download Taxi Data (CSV)\n",
    "   - **Install `wget` using Homebrew:**  \n",
    "     ```bash\n",
    "     brew install wget\n",
    "     ```\n",
    "   - **Use CLI to run:**  \n",
    "     ```bash\n",
    "     wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\n",
    "     ```\n",
    "\n",
    "### Read CSV with Pandas\n",
    "\n",
    "- **URL for compressed taxi data file:**  \n",
    "  - `url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"`\n",
    "\n",
    "- **Extract file name from URL:**  \n",
    "  - ```python\n",
    "    csv_name = url.split(\"/\")[-1]\n",
    "- **Read CSV directly into Pandas DataFrame:**\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv(csv_name)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab5864",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Step 4: Generate Postgres Schema from DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f7b89",
   "metadata": {},
   "source": [
    "### Generate Postgres Schema \n",
    "- Use `pd.io.sql.get_schema()` to create DDL from the DataFrame.  \n",
    "- Convert pickup/dropoff columns from text to datetime using `pd.to_datetime()` for accurate SQL types. \n",
    "- Create SQLAlchemy engine to connect pandas with Postgres.\n",
    "- Generate Postgres-specific DDL using `get_schema()` with the engine connection. This output defines the table structure Pandas will create in Postgres.\n",
    "\n",
    "### Check that the table was created succesfully \n",
    "\n",
    "- Run pgcli to connect to your Postgres container:\n",
    " ```bash\n",
    "     pgcli -h localhost -p 5432 -u root -d nyc_taxi\n",
    "```\n",
    "- Once in your postgres container, get list of tables\n",
    "```bash\n",
    "     \\dt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca3406",
   "metadata": {},
   "source": [
    "## üöï Step 5: Batch Load Data into Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e6f88",
   "metadata": {},
   "source": [
    "### Batch Ingestion Setup\n",
    "- Read CSV in chunks of 100,000 rows to avoid memory overload using `pd.read_csv` with `iterator=True` and `chunksize=100000`.\n",
    "- Use `next(df_iter)` to fetch the first chunk.\n",
    "- Print length of the chunk to confirm batch size.\n",
    "\n",
    "### Table Creation and Data Ingestion\n",
    "- Use `df.head(0)` to extract just the table schema (no data) and create a fresh table in Postgres with `if_exists='replace'`.\n",
    "- Insert the first chunk of data with `to_sql(if_exists='append')`.\n",
    "- Check for duplicates using `df.duplicated().sum()` to verify no double imports.\n",
    "- Continue batch ingestion with a for loop over `df_iter` to append remaining chunks to the table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789024c0",
   "metadata": {},
   "source": [
    "---\n",
    "### Additonal Notes\n",
    "<br>\n",
    "\n",
    "#### Key Docker Concepts\n",
    "| **Concept**   | **Example**                        | **What It Means**                                         |\n",
    "|---------------|------------------------------------|------------------------------------------------------------|\n",
    "| **Image**     | `python:latest`, `postgres:15`     | A snapshot blueprint ‚Äî like a cake recipe                  |\n",
    "| **Container** | `docker run -it python:latest`     | A live instance of that image ‚Äî like a baked cake          |\n",
    "| **Dockerfile**| `FROM python:3.12 ...`             | A way to define your own image ‚Äî ingredients + steps       |\n",
    "| **Build**     | `docker build -t myimage .`        | Turn the Dockerfile into an image                          |\n",
    "| **Run**       | `docker run -it myimage`           | Create a container from your image                         |\n",
    "| **EntryPoint**| `--entrypoint=bash`                | Override the default \"what to do when container starts\"    |\n",
    "| **Volume**    | `-v $(pwd):/app` (later)           | Mount your local files into container (for persistence)    |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
