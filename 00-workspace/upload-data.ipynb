{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f69509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12                1   \n",
      "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19                1   \n",
      "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06                1   \n",
      "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01                0   \n",
      "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21                1   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           2.10           1                  N           142            43   \n",
      "1           0.20           1                  N           238           151   \n",
      "2          14.70           1                  N           132           165   \n",
      "3          10.60           1                  N           138           132   \n",
      "4           4.94           1                  N            68            33   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2          8.0    3.0      0.5        0.00           0.0   \n",
      "1             2          3.0    0.5      0.5        0.00           0.0   \n",
      "2             1         42.0    0.5      0.5        8.65           0.0   \n",
      "3             1         29.0    0.5      0.5        6.05           0.0   \n",
      "4             1         16.5    0.5      0.5        4.06           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3         11.80                   2.5  \n",
      "1                    0.3          4.30                   0.0  \n",
      "2                    0.3         51.95                   0.0  \n",
      "3                    0.3         36.35                   0.0  \n",
      "4                    0.3         24.36                   2.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# URL for taxi data\n",
    "url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz\"\n",
    "\n",
    "# Extract file name from URL\n",
    "\n",
    "csv_name = url.split(\"/\")[-1]\n",
    "\n",
    "# Read compressed CSV directly into a dataframe\n",
    "\n",
    "df = pd.read_csv(csv_name, nrows=100)\n",
    "\n",
    "print(df.head()) #print first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yellow_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TEXT,\n",
      "  \"tpep_dropoff_datetime\" TEXT,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Use pandas get_schema to convert dataframe into DDL (data definition language)\n",
    "\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdcee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"yellow_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Convert pickup and dropoff columns from text to datetime objects\n",
    "\n",
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "\n",
    "# Print updated SQL schema with the new datetime columns\n",
    "\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e27e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Need to create a SQLAlchemy 'engine' for pandas to connect to Postgres container\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/nyc_taxi')\n",
    "\n",
    "# Generate DDL (CREATE TABLE...) to send to postgres specifically \n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))\n",
    "\n",
    "# This output is the SQL that Pandas will use to create the table in Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bff004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "#Define batch ingestion to Postgres: Read CSV in chunks of 100,000 rows to avoid overloading memory\n",
    "\n",
    "df_iter = pd.read_csv(csv_name, iterator= True, chunksize=100000)\n",
    "\n",
    "#Call next(df_iter) to get the first chunk of the iterator \n",
    "df = next(df_iter)\n",
    "\n",
    "#print how many rows are in this chunk (length of the iterator)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the schema only (no data yet) by using .head(0) to select first 0 rows\n",
    "df.head(0)\n",
    "\n",
    "# Call to_sql to create table in Postgres; if_exists='replace' drops the table if it already exists and creates a fresh one\n",
    "\n",
    "df.head(0).to_sql(name= 'yellow_taxi_data', con= engine, if_exists= 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d049bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start to load data into the table \n",
    "df.to_sql(name= 'yellow_taxi_data', con= engine, if_exists= 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e5b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows found: 0\n"
     ]
    }
   ],
   "source": [
    "#Check if any duplicates since we just ran the last cell twice. \n",
    "dupes_count = df.duplicated().sum()\n",
    "print(f\"Total duplicate rows found: {dupes_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3b5df71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested chunk 1, took 3.712seconds\n",
      "Ingested chunk 2, took 3.638seconds\n",
      "Ingested chunk 3, took 3.489seconds\n",
      "Ingested chunk 4, took 3.611seconds\n",
      "Ingested chunk 5, took 3.638seconds\n",
      "Ingested chunk 6, took 3.923seconds\n",
      "Ingested chunk 7, took 3.600seconds\n",
      "Ingested chunk 8, took 3.574seconds\n",
      "Ingested chunk 9, took 3.591seconds\n",
      "Ingested chunk 10, took 3.660seconds\n",
      "Ingested chunk 11, took 3.622seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/whjpvhfd7yg_pntm9383gb8c0000gn/T/ipykernel_15282/3852880683.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, df in enumerate(df_iter):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested chunk 12, took 3.548seconds\n",
      "Ingested chunk 13, took 2.272seconds\n"
     ]
    }
   ],
   "source": [
    "#Continue ingesting data in batches using for loop \n",
    "#time each ingestion and print how look it took\n",
    "\n",
    "from time import time \n",
    "\n",
    "for i, df in enumerate(df_iter): \n",
    "    \n",
    "    start_t = time()\n",
    "\n",
    "    df.to_sql(name='yellow_taxi_data', con=engine, if_exists= 'append')\n",
    "\n",
    "    end_t = time()\n",
    "    print(f'Ingested chunk {i +1}, took {end_t - start_t:.3f}seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
